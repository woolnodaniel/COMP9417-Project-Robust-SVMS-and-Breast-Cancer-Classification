{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Solutions: Testing Decision Trees, GNB, Neural Network, Non-Robust SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data and split into Training and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>...</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1</td>\n",
       "      <td>2.110995</td>\n",
       "      <td>0.721473</td>\n",
       "      <td>2.060786</td>\n",
       "      <td>2.343856</td>\n",
       "      <td>1.041842</td>\n",
       "      <td>0.219060</td>\n",
       "      <td>1.947285</td>\n",
       "      <td>2.320965</td>\n",
       "      <td>-0.312589</td>\n",
       "      <td>...</td>\n",
       "      <td>1.901185</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>1.752563</td>\n",
       "      <td>2.015301</td>\n",
       "      <td>0.378365</td>\n",
       "      <td>-0.273318</td>\n",
       "      <td>0.664512</td>\n",
       "      <td>1.629151</td>\n",
       "      <td>-1.360158</td>\n",
       "      <td>-0.709091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1</td>\n",
       "      <td>1.704854</td>\n",
       "      <td>2.085134</td>\n",
       "      <td>1.615931</td>\n",
       "      <td>1.723842</td>\n",
       "      <td>0.102458</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>0.693043</td>\n",
       "      <td>1.263669</td>\n",
       "      <td>-0.217664</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536720</td>\n",
       "      <td>2.047399</td>\n",
       "      <td>1.421940</td>\n",
       "      <td>1.494959</td>\n",
       "      <td>-0.691230</td>\n",
       "      <td>-0.394820</td>\n",
       "      <td>0.236573</td>\n",
       "      <td>0.733827</td>\n",
       "      <td>-0.531855</td>\n",
       "      <td>-0.973978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>2.045574</td>\n",
       "      <td>0.672676</td>\n",
       "      <td>0.577953</td>\n",
       "      <td>-0.840484</td>\n",
       "      <td>-0.038680</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>0.105777</td>\n",
       "      <td>-0.809117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561361</td>\n",
       "      <td>1.374854</td>\n",
       "      <td>0.579001</td>\n",
       "      <td>0.427906</td>\n",
       "      <td>-0.809587</td>\n",
       "      <td>0.350735</td>\n",
       "      <td>0.326767</td>\n",
       "      <td>0.414069</td>\n",
       "      <td>-1.104549</td>\n",
       "      <td>-0.318409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1</td>\n",
       "      <td>1.838341</td>\n",
       "      <td>2.336457</td>\n",
       "      <td>1.982524</td>\n",
       "      <td>1.735218</td>\n",
       "      <td>1.525767</td>\n",
       "      <td>3.272144</td>\n",
       "      <td>3.296944</td>\n",
       "      <td>2.658866</td>\n",
       "      <td>2.137194</td>\n",
       "      <td>...</td>\n",
       "      <td>1.961239</td>\n",
       "      <td>2.237926</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>1.653171</td>\n",
       "      <td>1.430427</td>\n",
       "      <td>3.904848</td>\n",
       "      <td>3.197605</td>\n",
       "      <td>2.289985</td>\n",
       "      <td>1.919083</td>\n",
       "      <td>2.219635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.808401</td>\n",
       "      <td>1.221792</td>\n",
       "      <td>-1.814389</td>\n",
       "      <td>-1.347789</td>\n",
       "      <td>-3.112085</td>\n",
       "      <td>-1.150752</td>\n",
       "      <td>-1.114873</td>\n",
       "      <td>-1.261820</td>\n",
       "      <td>-0.820070</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.410893</td>\n",
       "      <td>0.764190</td>\n",
       "      <td>-1.432735</td>\n",
       "      <td>-1.075813</td>\n",
       "      <td>-1.859019</td>\n",
       "      <td>-1.207552</td>\n",
       "      <td>-1.305831</td>\n",
       "      <td>-1.745063</td>\n",
       "      <td>-0.048138</td>\n",
       "      <td>-0.751207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0            1     1.097064     -2.073335        1.269934   0.984375   \n",
       "1            1     1.829821     -0.353632        1.685955   1.908708   \n",
       "2            1     1.579888      0.456187        1.566503   1.558884   \n",
       "3            1    -0.768909      0.253732       -0.592687  -0.764464   \n",
       "4            1     1.750297     -1.151816        1.776573   1.826229   \n",
       "..         ...          ...           ...             ...        ...   \n",
       "564          1     2.110995      0.721473        2.060786   2.343856   \n",
       "565          1     1.704854      2.085134        1.615931   1.723842   \n",
       "566          1     0.702284      2.045574        0.672676   0.577953   \n",
       "567          1     1.838341      2.336457        1.982524   1.735218   \n",
       "568          0    -1.808401      1.221792       -1.814389  -1.347789   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0           1.568466          3.283515        2.652874             2.532475   \n",
       "1          -0.826962         -0.487072       -0.023846             0.548144   \n",
       "2           0.942210          1.052926        1.363478             2.037231   \n",
       "3           3.283553          3.402909        1.915897             1.451707   \n",
       "4           0.280372          0.539340        1.371011             1.428493   \n",
       "..               ...               ...             ...                  ...   \n",
       "564         1.041842          0.219060        1.947285             2.320965   \n",
       "565         0.102458         -0.017833        0.693043             1.263669   \n",
       "566        -0.840484         -0.038680        0.046588             0.105777   \n",
       "567         1.525767          3.272144        3.296944             2.658866   \n",
       "568        -3.112085         -1.150752       -1.114873            -1.261820   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         2.217515  ...      1.886690      -1.359293         2.303601   \n",
       "1         0.001392  ...      1.805927      -0.369203         1.535126   \n",
       "2         0.939685  ...      1.511870      -0.023974         1.347475   \n",
       "3         2.867383  ...     -0.281464       0.133984        -0.249939   \n",
       "4        -0.009560  ...      1.298575      -1.466770         1.338539   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564      -0.312589  ...      1.901185       0.117700         1.752563   \n",
       "565      -0.217664  ...      1.536720       2.047399         1.421940   \n",
       "566      -0.809117  ...      0.561361       1.374854         0.579001   \n",
       "567       2.137194  ...      1.961239       2.237926         2.303601   \n",
       "568      -0.820070  ...     -1.410893       0.764190        -1.432735   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2.001237          1.307686           2.616665         2.109526   \n",
       "1      1.890489         -0.375612          -0.430444        -0.146749   \n",
       "2      1.456285          0.527407           1.082932         0.854974   \n",
       "3     -0.550021          3.394275           3.893397         1.989588   \n",
       "4      1.220724          0.220556          -0.313395         0.613179   \n",
       "..          ...               ...                ...              ...   \n",
       "564    2.015301          0.378365          -0.273318         0.664512   \n",
       "565    1.494959         -0.691230          -0.394820         0.236573   \n",
       "566    0.427906         -0.809587           0.350735         0.326767   \n",
       "567    1.653171          1.430427           3.904848         3.197605   \n",
       "568   -1.075813         -1.859019          -1.207552        -1.305831   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                2.296076        2.750622                 1.937015  \n",
       "1                1.087084       -0.243890                 0.281190  \n",
       "2                1.955000        1.152255                 0.201391  \n",
       "3                2.175786        6.046041                 4.935010  \n",
       "4                0.729259       -0.868353                -0.397100  \n",
       "..                    ...             ...                      ...  \n",
       "564              1.629151       -1.360158                -0.709091  \n",
       "565              0.733827       -0.531855                -0.973978  \n",
       "566              0.414069       -1.104549                -0.318409  \n",
       "567              2.289985        1.919083                 2.219635  \n",
       "568             -1.745063       -0.048138                -0.751207  \n",
       "\n",
       "[569 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('processed_data.csv')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 25) (569,)\n"
     ]
    }
   ],
   "source": [
    "# split into features and classification\n",
    "X = ds.drop('diagnosis', axis=1)\n",
    "y = ds['diagnosis']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test set: split value 0.8\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "num_training_items = X_train.shape[0]\n",
    "num_test_items = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are not many training items, we restrict the minimum number of samples at each leaf to avoid overfitting to 2% of the training items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', min_samples_leaf=9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=round(0.02*num_training_items))\n",
    "tree.fit(X_train,y_train)\n",
    "print(f'Decision Tree Accuracy: {tree.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes classifiers that we want to test is the Gaussian, since our data is normalised and real. Since Naive Bayes classifiers have the assumption of independence of features, we need to be careful. \n",
    "\n",
    "The features for this problem contain a mixture of means, standard errors, and extremal (worst-case) measurements. For example, the features contain the radius mean, standard deviation, and extremal values. Clearly, these three features will not fall under the NB assumption of independence, as they are three different kinds of measures of the same fundamental feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'radius_se', 'perimeter_se',\n",
       "       'area_se', 'compactness_se', 'concavity_se', 'concave points_se',\n",
       "       'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst',\n",
       "       'smoothness_worst', 'compactness_worst', 'concavity_worst',\n",
       "       'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have 9 mean, 6 standard-error, and 10 extremal measurements, we will only keep the extremal measurements. That way, we will have observations for each fundamental feature, all of the same kind, and do not lose any fundamental features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = ['radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', \\\n",
    "                  'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
    "X_train_NB = X_train[features_to_keep]\n",
    "X_test_NB = X_test[features_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_NB,y_train)\n",
    "print(f'Gaussian NB Accuracy: {gnb.score(X_test_NB,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement a neural network via the method `MLPClassifier` provided by `sklearn`. The classifier is a Multi-Layered Perceptron, with loss function given by the Cross Entropy loss function. We use a sigmoid (logistic) activation at the output (as our prediction should be 0 or 1), and a tanh activation at the hidden layers. There are two hidden layers in the model: for input of size `num_features`, the first hidden layer is twice the size, and the second is 4 times the size of the input. Finally, we use an adaptive learning rate (i.e. decreases with training), initialised at 0.05. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=(50, 100),\n",
       "              learning_rate='adaptive', learning_rate_init=0.01, solver='sgd')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "nn = MLPClassifier(hidden_layer_sizes=(2*num_features,4*num_features), activation='tanh', \\\n",
    "                   solver='sgd', learning_rate='adaptive', learning_rate_init=0.01)\n",
    "nn.fit(X_train,y_train)\n",
    "print(f'Neural Network Accuracy: {nn.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4: Simplified SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our base Support Vector Machine implementation, we have chosen a sigmoidal kernel function, as this is related to the tanh-activated hidden layers in the neural network, and so makes the two models comparable (more precisely a sigmoidal kernel function implements a classifier that is equivalent to a two-layer perceptron with tanh activation). \n",
    "\n",
    "First, we need to determine the regularization parameter `C` via a grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Accuracy of 0.9824561403508771 achieved by r = 0.25\n"
     ]
    }
   ],
   "source": [
    "regs = np.arange(0,1.01,0.05)\n",
    "regs[0] = 0.01\n",
    "best_acc = 0.0\n",
    "best_r = 0\n",
    "for r in regs:\n",
    "    svm = SVC(C=r, kernel='sigmoid', gamma='scale')\n",
    "    _ = svm.fit(X_train, y_train)\n",
    "    acc = svm.score(X_test, y_test)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_r = r\n",
    "print(f'Highest Accuracy of {best_acc} achieved by r = {best_r}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.25, kernel='sigmoid')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Accuracy: 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(C=0.25, kernel='sigmoid', gamma='scale')\n",
    "svm.fit(X_train, y_train)\n",
    "print(f'Support Vector Machine Accuracy: {svm.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this simple set up, we can see that the SVM performs best out of our four methods. This justifies the further investigation into different formulations for SVMs, and their ability to maintain powerful classification under noisy data and uncertainty. This will be assessed in the following section. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
